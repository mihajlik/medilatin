%
%	TSD 2017
%	LaTeX Template for Camera-ready Version
%
%	Rel. 2013-05-20 by Ivan Habernal (habernal@kiv.zcu.cz)
%	Rel. 2014-11-21 by Kamil Ekstein (kekstein@kiv.zcu.cz)
%   Rel. 2015-02-23 by Pavel Kral    (pkral@kiv.zcu.cz)
%	Rel. 2017-02-06 by Kamil Ekstein (kekstein@kiv.zcu.cz)
%
%	Based upon Springer's LNCS series template.
%
\documentclass[runningheads,a4paper]{llncs}

\usepackage{times}
\usepackage{amssymb}
\setcounter{tocdepth}{3}
\usepackage{graphicx}
\usepackage{url}

% TSD 2017: Add any additional packages you use in your manuscript
% -----pack
% \usepackage{xxx}
% -----

% TSD 2017: Add your custom definitions etc., if required
% -----misc
% \newcommand{\xxx}[1]{[#1]}
% -----

\newcommand{\keywords}[1]{\par\addvspace\baselineskip
\noindent\keywordname\enspace\ignorespaces#1}

% TSD2017: Put your e-mail addresses here
\urldef{\mailsa}\path|{author1, author2}@institute1.org|
\urldef{\mailsb}\path|author3@institute2.org|
%\urldef{\mailsc}\path|other_mails_if_needed|    

\begin{document}

% TSD 2017: Put your title here (please, use capitalization, see e.g.
% http://en.wikibooks.org/wiki/Basic_Book_Design/Capitalizing_Words_in_Titles)
\title{Cross-Native-Language Medieval Latin Dictation}

% TSD 2017: a short form should be given in case the title is too long for the running head
\titlerunning{Cross-Native-Language Medieval Latin Dictation}

% TSD 2017: Author's names. Chinese authors should write their first names(s)
% in front of their surnames. This ensures that the names appear correctly in
% the running heads and the author index.
% If the names contain accented characters, please use escape codes
% (refer to http://en.wikibooks.org/wiki/LaTeX/Special_Characters#Escaped_codes)
\author{Firstname1 Surname1 \and Firstname2 Surname2 \and Firstname3 Surname3}

% TSD 2017: For authors from different institutions, please use the following
% form including institution reference
% \author{Firstname1 Surname1\inst{1} \and Firstname2 Surname2 \inst{2}}

% TSD 2017: Author's names for headings. For 1-2 authors, use the following form
\authorrunning{Firstname1 Surname1 and Firstname2 Surname2}
% TSD 2017: For more than 2 authors, please, use the following
% \authorrunning{Name1 Surname1 et al.}

% TSD 2017: The authors' affiliations
\institute{Affiliation1, Institute1, Address \\
% TSD 2017: optional url
\url{www.website.org} \\
\mailsa\\
% TSD 2017: For authors from different institutions, add 2nd institution, etc.
% \and
% Affiliation2, Institute2, Address \\
% \url{www.website.org} \\
% \mailsb\\
}

% TSD 2017: Put all authors' names to the proceeding index (surname, first name)
\index{Surname1, Firstname1}
\index{Surname2, Firstname2}

\toctitle{} \tocauthor{}

\maketitle

%
%
%	TSD2017 SUBMISSION TEXT
%
%
\begin{abstract}
% TSD 2017:
We present a medieval Latin charter dictation system which can be of great help for preserving Latin language documents from the same era, as optical character recognition systems are often challenged by historic documents.
Our goal is to develop a cross-native-language medieval Latin recognizer that performs better than single-language recognizers with mono-lingual speakers.
Our targets are the Visegrad languages (based on a geographical grouping), with native speakers of Czech, Hungarian and Polish.
The baseline systems we start with are separately trained grapheme-based acoustic models for all the above three languages. 
We introduce two pronunciation modeling techniques to outperform the separately trained models.
The first one is using grapheme-to-phoneme (G2P) mapping with Latin-specific pronunciation rules implemented. 
The second one is training a Unified Simplified Grapheme (UGS) acoustic model that can deal with cross-native-language variations.
We show that our methods outperform our baseline system, reducing the WER by ...\% and ...\% respectively.
We also observe, that adding more languages to our joint acoustic model further reduces the WER.
% TSD 2017: keywords, comma-separated
\keywords{G2P, Latin, low resource speech recognition, unified simplified grapheme modeling}
\end{abstract}

\section{Introduction}
The pronunciation of Latin texts mainly depends on the era and region of their origin~\cite{regional}.
Apart from the two widely studied classical and ecclesiastical pronunciation styles~\cite{allen78}, regional pronunciations exists emerging after the post-classical era.
One of these pronunciation groups is the Slavic-Uralic~\cite{regional} one, which uses the same pronunciation rules, described in detail in Section~\ref{g2p}.
Although the target pronunciation is considered to be uniform for this group, it is also has to be taken into account, that the acoustic base of the different native languages varies, which can lead to different speakers pronouncing the same words differently.
It also has to be noted, that apart from the variations in the pronunciations, orthographic and linguistic variations are also exhibited through regions.

This raises the question of how to create a speech recognition system which has to deal with uniform pronunciations for native speakers of different languages reading linguistically different texts.
We propose a system that is suitable for medieval Latin dictation for all speakers from the Visegrad region.\footnote{Sadly, but for this paper, although it belongs to the Visegrad region, the Slovakian language is not included in our experiments, due to the lack of speech data.}
The system we develop is a joint system that can deal with both the variability in the speakers' pronunciations when speaking medieval Latin, and the grammatical/lexical variabilities of the texts.
Therefore, it is important to collect in-domain textual/language data for the language model from the relevant geographican regions and time.
We describe the data acquisition process in section~\ref{text}.

Our baseline system consists of separately trained grapheme-based acoustic models for the three Visegrad languages (Czech, Hungarian and Polish). 
These separately trained models work good with their respective native speakers, but perform poorly with speakers of different native languages.
We apply two different pronunciation modeling techniques to develop models that are superior to the baseline.
The first one, dicussed in detail in Section~\ref{g2p}, is based on the assumption that 
The second method we use is USGM (Unified Simplified Grapheme Modeling), where a joint/minimal/common grapheme inventory is established for all the languages paricipating in the joint acoustic model training.
We describe the USG method in Section~\ref{usg}.
Evaluation of the baseline systems and both above approaches is presented in section~\ref{results}.

\subsection{Related work}
Similar work has been done for multi-dialectal languages such as Arabic in~\cite{elfeky16} where jointly trained acoustic models were outperformed by methods that unify dialect specific-acoustic models using knowledge distillation and multitask learning.

To our knowledge, no previous work has been done on medieval Latin speech recognition, nor on classical Latin for that matter.
%TODO: mention espeak TTS ?

\section{Data}
\subsection{Textual data}\label{text}
As part of out inquiry was to cover linguistic variability accross the Visegrad region, aquiring textual data posed a few challenges.
First of all, textual data are scarce for medieval Latin, and texts originating from this geographical region are even more scarce.
Additionally, most of the available sources mix local languages and Latin, with no metadata to separate them.
For the scope of this paper, we collected monolingual texts only.
\subsubsection{Training data}
A smaller amount of in-domain data (medieval charters) were collected from~\cite{monasterium} (Monasterium), with an overall of 480k tokens.
These documents are originating from the Hungarian Kingdom, from 1000 to 1524 AD.
To increase the vocabulary size of the language model, we collected a relatively larger (but still small, compared to state-of-the-art language models used in speech recognition) 1.3 token corpus from~\cite{latinlibrary} (LatinLibrary).
This corpus consists of literary and historical texts from the post-classical era.
In spite of our efforts, at the time of writing this paper, we could not gather textual data from the age and area of the Kingdoms of Bohemia and Poland.
\subsubsection{Test data}\label{textest}
Using independent sources three-three charters were selected from the Kingdoms of Bohemia (CZ), Hungary (HU) and Poland (PL), from around 1200-1300 AD, for development and test data.
The dev set was used for evaluating the language model, and to test the performance of our recognizers.
Both dev and test sets were read out loud by historians fluent in medieval Latin.
\subsubsection{Alternate spellings}
One interesting feature of the acquired corpora is that they contain a significant number of spelling variants.
Having spelling variants in the corpus with identical pronunciation introduces noise, and thus has a negative effect on recognition results.
To detect the spelling variants we took all pairs in the pronunciation dictionary whose pronunciation were identical, and used context and expert knowledge to decide whether the pair of equivalent pronunciations are spelling variants or homophones.
We obtained a unified spelling for these variants by favouring the more frequent variant in the corpus (e.g. \textit{maiestati} to \textit{majestati}).
Resolving spelling variants resulted in a more consistent corpus in terms of perplexity (reducing it from 775 to 672), and reduced the OOV rate by 0.8\%.
%TODO: verbatim text excerpts (cz).
\subsubsection{Language model}
The language models we built from the two corpora were estimated with the SRI Language Modeling toolkit (SRILM)~\cite{srilm} using modified Kneser-Ney smoothing method.
After estimating the mixture parameter, linear interpolation was used.

The perplexity measures on the dev data showed, that the Monasterium corpus originating from the time and era of the Hungarian Kingdom was indeed best fitting with the Hungarian subset of the test data with a perplexity of 82, and $0.9\%$ OOV rate.
Adding the LatinLibrary corpus increased the perplexity significantly, but reduced the OOV rate by $7\%$ on the overall test data, as well as the WER, so we decided to use the interpolated language model.

\subsection{Speech data}
\subsubsection{Training data}
%TODO: references, hours.
For Czech and Hungarian the Speecon databases~\cite{czech}~and~\cite{hungarian} and broadcast news speech data was used.
For Polish, only broadcast news data~\cite{polish} was available, comprising 31 hours of manually transcribed speech.
\subsubsection{Test data}
Native speakers of Czech, Hungarian and Polish all of whom have experince with medieval Latin were asked to record the three dev and test sets described in Section~\ref{textest}.
The recording conditions were accurately controlled: close‒talking microphones, quiet, non reverberant acoustic environment, fluent, flawless speech, and at least 16 kHz, 16 bit (linear PCM) encoding.
No instructions were given regarding the pronunciation, the speakers were using their expertise on medieval Latin pronunciation rules combined with their native language pronunciation.
The overall length of the recorded test speech was around 30 minutes.

\section{Acoustic modeling}\label{AM}
Building an acoustic model for speech recognition requires long hours of trancribed speech.
As of today (medieval) Latin is not spoken natively, and as to our knowledge, there is no recorded speech database.
One obvious way to handle this problem is build/create a medieval Latin database; a proposition that requires lot of time, resources and trained speakers of medieval Latin. 
Another way of circumvent the lack of available speech data is to use speech data of spoken languages, preferably those ones whose native speakers are going to use the dictation system. 

For all the different pronunciation modeling methods, the acoustic models were trained as follows.
Mel-Frequency Cepstrum $+$ Energy features were used with Linear Discriminant Analysis (LDA) + Maximum Likelihood Linear Transformation (MLLT), with a splice context of $\pm4$ frames, 10 ms of frame shift.
$9\times40$ dimensional spliced up feature vectors served as input to the feed‒forward, 6 hidden‒layer neural network with p‒norm [16] activation function.
Prior to DNN training, a Gauss Mixture Model (GMM) pre-training was performed.
Clustering and Regression Tree (CART)~\cite{kaldi} was applied to obtain across‒word context dependent shared state phone (or graph) models and their time alignment.
The number of senones (and so the size of the DNN softmax output layer) was between 7.000 and 11.000 depending on the nature of the training data.
The size of the hidden layers was kept constantly on 2.000.
A minibatch size of 512, an initial learning rate of 0.1, and final learning rate of 0.01 was applied in 20 epochs using the KALDI toolkit~\cite{kaldi}.
\subsection{Grapheme-based pronunciation modeling}\label{grapheme}
For our three separately trained baseline systems grapheme-based pronunciation models were used.
It was based on the same principles described in detail in Section~\ref{simplified}, namely mapping the graphemes not present in the Latin grapheme set to their normalized counterparts.
\subsection{Grapheme to phoneme mapping (G2P)}\label{g2p}
The Czech and Hungarian phoneme-based acoustic models we used were trained with G2P mapping between orthographic transcriptions and native phonemes.
The G2P rules were composed with the language model within a WFST framework~\cite{wfst}.
But since we were using these models for recognizing medieval Latin speech spoken by native speakers of Czech, Hungarian and Polish, Latin-specific pronunciation rules also had to be implemented. 
These include a few context independent digraph mappings, and a few context dependent rewrite rules, summarized in Table~\ref{tbl:digraph} and Table~\ref{tbl:context} respectively, for both Czech and Hungarian.

\begin{table}\label{tbl:digraph}
	\centering
	\caption{Latin digraph context-insensitive rewrite rules.}
	\begin{tabular}{l|rrrr}
	\hline
	Digraph & ae & oe & ph & qu \\
	\hline
	CZ & e & oe & f & kv \\
	HU & e & \o & f & kv \\
	\hline
	\end{tabular}
\end{table}

\begin{table}\label{tbl:context}
	\centering
	\caption{Latin context-sensitive rewrite rules. V: vowel, VP: palatal vowel, C: consonant, $*$: zero or any, \string^: beginning of word, $[\string^stx]$: not s, t or x.}
	\begin{tabular}{l|cc|cc|cc|cc}
	\hline
	GR & c & c & ch & ch & gu & gu & ti & ti \\
	PH & ts & k & h & k & gv & gu & tsi & ti \\
	\hline
	rule & \multicolumn{1}{c|}{cVP} & \multicolumn{1}{c|}{VNP} & \multicolumn{1}{c|}{VC*ch} & \multicolumn{1}{c|}{\string^C*ch} & \multicolumn{1}{c|}{guV} & \multicolumn{1}{c|}{guC} & \multicolumn{1}{c|}{$[\string^stx]$tiV} & \multicolumn{1}{c|}{tiC} \\
	\hline
	\end{tabular}
\end{table}

The Latin alphabet we extracted from our corpora (see Section~\ref{text}) consisted of 24 elements.
%The interpolated LM described in Section 2.1 was composed with the appropriate phoneme or grapheme based pronunciation dictionaries in the Weighted finite State Transducer (WFST) framework [17]. After the usual optimization processes the WFST recognition network translates between generalized triphones (or trigraphs) and words. 
%The mapping of triphones (trigraphs) to senones is performed in the VoXerver WFST‒HMM‒DNN decoder. Approximately the same speed,  faster than real‒time decoding was performed in all experiments.
\subsection{Unified Simplified Grapheme Modeling}\label{usg}
The second method we propose for cross-native-language Latin dictation is Unified Simplified Grapheme (USG) pronunciation modeling technique, which comes in play when joint acoustic models are being trained to support recognition across multiple languages.
\subsubsection{Unified}
The joint acoustic model requires a unified grapheme inventory for the trainig, so that only thosegraphemes are in the model that are in the intersection of the different grapheme inventory sets of the training languages.
Those letters that are not in this intersection are mapped to their normalized forms, e.g. it had a diacritic mark (acute, caron, etc.) on it, we mapped it back to its normalized form (\texttt{\v{r}} to \texttt{r}, etc.).
\subsubsection{Simplified}\label{simplified}
Since the target dictation language was medieval Latin, the remaining unified grapheme set also had to be simplified to the Latin grapheme set, e.g. \texttt{\'{o}} to \texttt{o}.
Further than that, those graphemes that are non-native to Latin, and can straightforwardly mapped to a native Latin grapheme(s), were also replaced.
These are mappings from \texttt{x} to \texttt{ks}, \texttt{y} to \texttt{i} and \texttt{w} to \texttt{v}.
As a result, a unified and simplified grapheme inventory set was produced, compatible with medieval Latin.
The USG units were then used as acoustic model units in the training.
\section{Experimental results}\label{results}
We conducted expeiments on medieval Latin, spoken by native speakers of three languages (Czech, Hungarian and Polish), where the test are texts originating from different regions, as described in Sections~\ref{AM}~and~\ref{text}.
We introduced two techniques to improve the recognition results of our separately trained grapheme-based models, described in~\ref{baseline}.
Our experimental results showed that both methods outperformed the baseline system.
\subsection{Latin-specific G2P rules results}
\subsection{USG results}
\begin{table}
\parbox{.45\linewidth}{
\centering
\caption{Polish grapheme-based baseline model. Size of acoustic model: 31 hours.}
\input{tables/pl_grapheme.tex}
}
\hfill
\parbox{.45\linewidth}{
\centering
\caption{Czech Latin-specific G2P model. Acoustic model size: 76 hours.}
\input{tables/cz_phoneme.tex}
}
\hfill
\parbox{.45\linewidth}{
\centering
\caption{Hungarian Latin-specific G2P model. Acoustic model size: 567 hours.}
\input{tables/hu_phoneme.tex}
}
\hfill
\parbox{.45\linewidth}{
\centering
\caption{USG model of Czech (76 hours), Hungarian (112 hours) and Polish (31 hours).}
\input{tables/cz_hu_pl_usg.tex}
}
\hfill
\parbox{.45\linewidth}{
\centering
\caption{USG model of Hungarian (112 hours), Polish (31 hours) and Roman (35 hours).}
\input{tables/hu_pl_ro_usg.tex}
}
\hfill
\parbox{.45\linewidth}{
\centering
\caption{USG model of Czech (76 hours), Polish (31 hours) and Roman (35 hours).}
\input{tables/cz_pl_ro_usg.tex}
}
\hfill
\parbox{.45\linewidth}{
\centering
\caption{USG model of Czech (76 hours), Hungarian (112 hours), Polish (31 hours) and roman (35 hours).}
\input{tables/cz_hu_pl_ro_usg.tex}
}
\end{table}
\subsubsection{Error analysis}
%TODO: why hu is better with usg model.
%TODO: why cz is better with hu phoneme model.
%TODO: why pl wer is so high.
\subsection{Conclusions}
In this paper, we presented two pronunciation modeling techniques for a cross-native-language medieval Latin dictation system to eliminate the efforts of digitizing medieval Latin charter data.
With the objective of outperforming the separately trained grapheme-based models, we presented two approaches: an expert G2P modeling, and UGS modeling.
The results showed...

Future research directions include acquiring a considerable amount of medieval speech and textual data.

% Bibliography
\bibliographystyle{splncs03}
\bibliography{tsd2017}

\end{document}
